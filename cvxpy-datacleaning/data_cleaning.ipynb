{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anne Katrine Falk 23APR2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make cell width follow width of notebook\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:95% !important;}</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# De-noising a series\n",
    "Compare Total Variation, Low-pass filter and Savitzky-Golay filter applied to a 1D signal which is mostly smooth, but has a number of sharp steps.\n",
    "\n",
    "**Total variation** is an optimisation approach, the **low-pass filter** is a 1.order exponential smoothing and the **Savitzky-Golay** filter is an approximation with a low-degree polynomium over a rolling window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General dependencies\n",
    "This section import the dependencies that are used allover. The dependencies for each de-noising method are imported in the respective sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib notebook\n",
    "matplotlib.rcParams['figure.figsize'] = (9, 4)\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods for creating noisy data with sharp steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_noisy_step(n_sample, around_value):\n",
    "    return (np.random.random(n_sample)-0.5 + around_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_noisy_step_input(n_step, samples_in_step):\n",
    "    step_height = np.random.random(n_step)*20\n",
    "    \n",
    "    noisy_step_input =  np.zeros(n_step * samples_in_step)\n",
    "    \n",
    "    for k in range(n_step):\n",
    "        for i in range(samples_in_step):\n",
    "            noisy_step_input[k*samples_in_step : (k+1)*samples_in_step] = create_noisy_step(samples_in_step, step_height[k])\n",
    "            \n",
    "    return noisy_step_input                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create noisy data with sharp steps\n",
    "The array x_noisy will be used as \"the noisy data\" in the rest of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 10 steps with 2000 samples in each - in total 20.000 samples\n",
    "x_noisy = create_noisy_step_input(n_step=10, samples_in_step=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the noisy data\n",
    "fig = plt.figure()\n",
    "plt.title('Constructed test data: Steps with noise')\n",
    "T = np.arange(0, len(x_noisy))\n",
    "plt.plot(T, x_noisy, label='x_noisy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Total variation\" -  an optimisation model for de-noising\n",
    "Total variation reconstruction (Boyd and Vandenberghe p. 314)\n",
    "\n",
    "**Total variation** reconstruction formulates an optimisation model with a cost function, which is a sum of two terms:\n",
    "- the least squares deviation from the noisy points\n",
    "- a regularization term, which is the one-norm of the difference operator $D$ applied to the optimisation variable $x$\n",
    "\n",
    "$$\\| x-x_{noisy} \\|_2^2 + \\delta \\| Dx \\|_1$$\n",
    "\n",
    "Using the 1-norm in the regularisation term is what \"does the magic\" in NOT easing the corners of the non-smooth steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "print(cp.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the optimisation variable\n",
    "The optimisation problem will optimise a vector of same size as the noisy input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = cp.Variable((len(x_noisy),)) #vector variables are defined with shape=(size,), not shape=(size,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check dimensions of x and x_noisy\n",
    "x.shape, x_noisy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the cost function using cvxpy expressions of the cvxpy variable x\n",
    "cvxpy has a built-in function for the \"total variation\"-term (the second term), cvxpy.tv. Note that **cvxpy.tv behaves according to whether the cvx-variable x is defined as a vector or as a matrix**.\n",
    "\n",
    "The below formulation of the cost function behaves unexpectedly, if x is defined as a matrix with one column x=cp.Variable((len(x_noisy),1), **use cp.Variable((len(x_noisy),)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First term is the 2-norm of (x-x_noisy), second term is the regularisation parameter (delta) times the total variation of x\n",
    "delta = 10\n",
    "cost = cp.sum(cp.square(x-x_noisy)) + delta*cp.tv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve the optimisation problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "problem = cp.Problem(cp.Minimize(cost))\n",
    "problem.solve() #  solve using the default open-source solver\n",
    "#problem.solve(solver=cp.MOSEK) #  solve using mosek. Requires a mosek license, and is approximately 4 times faster than the default\n",
    "problem.status, cost.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.title('Total variation de-noising')\n",
    "\n",
    "T = np.arange(0, len(x_noisy))\n",
    "plt.plot(T, x_noisy, label='x_noisy')\n",
    "plt.plot(T, x.value, label=f'reconstructed, $\\delta=${delta}')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the trade-off curve between $\\| x-x_{noisy} \\|_2^2$ and $\\| Dx \\|_1$\n",
    "This step solves optimisation problem for different values of delta. The goal is to explore the trade-off curve between the objectives. This is the same as the Pareto frontier.\n",
    "\n",
    "delta is defined as a cvxpy.Parameter. This has the implication that we can loop over delta (to explore the trade-off) without (re-)building the entire optimisation problem each time. When delta is defined as a parameter, the optimisation problem is defined (and compiled) once, and only delta is replaced before each call to problem.solve().\n",
    "\n",
    "A Parameter is the only entity, which can be changed _after_ cvxpy has compiled the problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calculate_tradeoff(delta_list):\n",
    "            \n",
    "    # lists to pick up the two competing terms in the objective value, the objective value itself and the optimal x\n",
    "    sq_err = []\n",
    "    total_var = []\n",
    "    obj = []\n",
    "    x_opt = []\n",
    "    \n",
    "    #  don't define x inside the loop because this is time-consuming for a large series - re-use instead\n",
    "    x = cp.Variable((len(x_noisy),)) \n",
    "    delta = cp.Parameter(nonneg=True)\n",
    "    \n",
    "    cost = cp.sum(cp.square(x-x_noisy)) + delta*cp.tv(x)\n",
    "    problem = cp.Problem(cp.Minimize(cost))\n",
    "\n",
    "    for d in delta_list:\n",
    "        print(f'Solving optimisation with delta = {d}')\n",
    "        delta.value = d\n",
    "\n",
    "        problem.solve() #  solve using the default open-source solver\n",
    "        #problem.solve(solver=cp.MOSEK) #  solve using mosek. Requires a mosek license, and is approximately 4 times faster than the default\n",
    "        \n",
    "        # append the result to the lists\n",
    "        sq_err.append(cp.sum(cp.square(x-x_noisy)).value)\n",
    "        total_var.append(cp.tv(x).value)\n",
    "        obj.append(cost.value)\n",
    "        x_opt.append(x.value)\n",
    "    return sq_err, total_var, obj, x_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NB! This step is the time-consuming step.\n",
    "delta_list = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.75, 1, 2, 10, 20]\n",
    "sq_err, total_var, obj, x_opt =calculate_tradeoff(delta_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# collect the results in a dataframe \n",
    "df = pd.DataFrame(data={'delta': delta_list, 'sq_err': sq_err, 'total_var': total_var, 'obj': obj, 'x_opt': x_opt})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the trade-off curve\n",
    "The trade-off curve for the bi-objective optimization problem $min (\\| x-x_{noisy} \\|_2^2, \\| Dx \\|_1)$ shows how the values of the two competing terms varies with different choices of $\\delta$. It shows that the higher value of $\\delta$ we choose, the larger does the (squared) deviation from the optimal value to the observations become. The hardest possible regularisation would result in $x_{opt}$ becoming a horizontal line (all $\\Delta x_i$ are zero). In this case $\\| x-x_{noisy} \\|_2^2 = \\| x_{noisy} \\|_2^2$, because we can assume that $x_{opt} = 0$.\n",
    "\n",
    "For $\\delta=10 $ and $\\delta = 20$ we approach this limit, where $\\| Dx \\|_1$ cannot be reduced much more. We want the optimisation to maintain only the sharp steps and iron out the high-frequency noise.\n",
    "\n",
    "The trade-off curve is also known as the Pareto frontier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the trade-off curve\n",
    "fig = plt.figure()\n",
    "plt.title('trade-off between $\\|\\| x_{opt}-x_{noisy} \\|\\|_2^2$ and $\\|\\| Dx \\|\\|_1$')\n",
    "plt.scatter(df['total_var'], df['sq_err'])\n",
    "plt.xlabel('$\\| \\| Dx \\| \\|_1$')\n",
    "plt.ylabel('$\\| \\| x_{opt}-x_{noisy} \\| \\|_2^2$')\n",
    "\n",
    "for i in df.index:\n",
    "    delta = df['delta'].iloc[i]\n",
    "    fig.axes[0].annotate(text = f'{delta}', xy = (df['total_var'].iloc[i], df['sq_err'].iloc[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total variation de-noising for different choices of $\\delta$\n",
    "You'll have to zoom to se the very slight difference between $\\delta=10$ and $\\delta=20$.\n",
    "\n",
    "$\\delta=1$ clearly leaves more of the noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.title('Total variation de-noising')\n",
    "\n",
    "T = np.arange(0, len(x_noisy))\n",
    "plt.plot(T, x_noisy, label='x_noisy')\n",
    "df_rows = [7, 9, 10]\n",
    "\n",
    "for i in df_rows:\n",
    "    delta = df['delta'].iloc[i]\n",
    "    plt.plot(T, df['x_opt'].iloc[i], label=f'reconstructed, $\\delta=${delta}')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lowpass filter\n",
    "The low-pass filter cuts frequencies above a threshold. The lower the threshold, the more noise is removed, but at the cost of an increasing phase-lag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import control\n",
    "print(control.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def lowpass_tf(a):\n",
    "    \"\"\"\n",
    "    Transfer function for exponential decay.\n",
    "    dx/dt + a*x = u\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    a : float\n",
    "    \"\"\"\n",
    "    # create a variable 's' to allow algebraic operations for SISO systems\n",
    "    s = control.tf('s')\n",
    "    # transfer function G(s)=1/(s+a) is scaled by a to get output 1 for s=0\n",
    "    return a/(s+a)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print the transfer function for a selected frequency\n",
    "print(lowpass_tf(a=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lowpass(x_noisy, frequency_list):\n",
    "    fig = plt.figure()\n",
    "    plt.title('Low-pass filter')\n",
    "    \n",
    "    T = np.arange(0, len(x_noisy))\n",
    "    plt.step(T,x_noisy, label='x_noisy')\n",
    "    for f in frequency_list:\n",
    "        _, Y, _ = control.forced_response(lowpass_tf(f), T, x_noisy, X0=x_noisy[0])\n",
    "        plt.step(T, Y, label=f'cut frequency = {f}')\n",
    "    plt.legend() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lowpass(x_noisy, [1, 0.1, 0.01])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Savitsky-Golay filter\n",
    "The Savitsky-Golay filter aproximates the data by a low-order polynomium over a rolling window. This approach works well for smooth data, but for data with sudden steps it tries to make a smooth transition, which results in overshoot/undershoot around the step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_savitzky_golay(x_noisy, window_list, polyorder):\n",
    "    \"\"\"\n",
    "    Calculate and plot the Savizky-Golay smoothing of a noisy series for a list of different windows\n",
    "    \n",
    "    x_noisy: np.ndarray\n",
    "        vector of noisy data\n",
    "    window_list: list of odd integers\n",
    "        The window length must be odd as the window is centered at the point in question and should have equal extent\n",
    "        on both sides.\n",
    "    polyorder: int\n",
    "        Order of the approximation polynomium    \n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    plt.title(f'Savitzky-Golay filter of order {polyorder}')\n",
    "    T = np.arange(0, len(x_noisy))\n",
    "    plt.step(T,x_noisy, label='x_noisy')\n",
    "    for window_length in window_list:\n",
    "        Y = signal.savgol_filter(x_noisy, window_length, polyorder=2)\n",
    "        plt.step(T, Y, label=f'window length = {window_length}')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_savitzky_golay(x_noisy, window_list=[25, 51, 101], polyorder=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Total variation, Low-pass and Savitzky-Golay\n",
    "The below plot compares the three de-noising methods. If you zoom to one of the corners of a step you will see:\n",
    "\n",
    "The Low-pass filter has a phase lag, i.e. it takes some time for the filtered signal to \"climb\" a step, and likewise the decline at the end of a step is delayed\n",
    "The Savitsky-Golay filter has an overshoot/undershoot around the step changes\n",
    "The Total variation masters the step changes while at the same time removing the noise during the steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_freq = 0.1 # for low-pass filter\n",
    "window_length = 25 # for Savitzky-Golay filter\n",
    "\n",
    "T = np.arange(0, len(x_noisy))\n",
    "_, x_lowpass, _ = control.forced_response(lowpass_tf(cut_freq), T, x_noisy, X0=x_noisy[0])\n",
    "x_savgol = signal.savgol_filter(x_noisy, window_length, polyorder=2)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.title('Low-pass and Savitzky-Golay and Total variation')\n",
    "\n",
    "plt.step(T, x_noisy, label='x_noisy')\n",
    "plt.step(T, x_lowpass, label=f'low-pass, cut frequency = {cut_freq}')\n",
    "plt.step(T, x_savgol, label=f'Savitzky-Golay, window length = {window_length}')\n",
    "plt.step(T, x.value, label=f'total variation, $\\delta=${delta}')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
