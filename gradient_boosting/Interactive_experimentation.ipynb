{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1ce5856-8405-41cb-8e95-c3a95701ddfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import catboost\n",
    "import ngboost\n",
    "import KTBoost.KTBoost as KTBoost\n",
    "import xgboost\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ba6588-7f59-4eda-8209-12560d928415",
   "metadata": {},
   "source": [
    "# Functions to get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8090284-035b-4133-907a-69921466e463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_data(nobs, noise_std, low=0, high=1):\n",
    "    coefficients = np.array([13, -10, 15])\n",
    "    x = np.random.uniform(size=[nobs, 3], low=low, high=high)\n",
    "    y = x @ coefficients + np.random.normal(size=nobs)*noise_std\n",
    "    sorted_inds = np.argsort(y)\n",
    "    y = y[sorted_inds]\n",
    "    x = x[sorted_inds, ...]\n",
    "    return x, y\n",
    "\n",
    "def nonlinear_data(nobs, noise_std, low=0, high=1):\n",
    "    x = np.random.uniform(size=[nobs, 3], low=low, high=high)\n",
    "    y = x[:, 0]**2 + 2*np.sin(x[:, 1]) + x[:, 1]*x[:, 2] + np.random.normal(size=nobs)*noise_std\n",
    "    sorted_inds = np.argsort(y)\n",
    "    y = y[sorted_inds]\n",
    "    x = x[sorted_inds, ...]\n",
    "    return x, y\n",
    "\n",
    "def get_train_test_data(nobs, noise_std, linear):\n",
    "    if linear:\n",
    "        x, y = linear_data(nobs, noise_std, low=-.7, high=.7)\n",
    "        xtest, ytest = linear_data(nobs, noise_std, low=-1, high=1)\n",
    "    else:\n",
    "        x, y = nonlinear_data(nobs, noise_std, low=-.7, high=.7)\n",
    "        xtest, ytest = nonlinear_data(nobs, noise_std, low=-1, high=1)\n",
    "    return x, y, xtest, ytest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f6eacf-313e-465f-934b-60fab25799ef",
   "metadata": {},
   "source": [
    "# Compare predictions from different methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cb36e26-4ea1-4251-8016-df22460fef82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cd2058a490a4e62b0c4aabc3a2676d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=505, description='nobs', max=1000, min=10), FloatSlider(value=0.0, descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "def func(nobs, noise_std, linear):\n",
    "    methods = {\n",
    "    'Linear regression': [LinearRegression(), {}],\n",
    "    'SKLearn GB': [GradientBoostingRegressor(), {}],\n",
    "    'NGB': [ngboost.NGBRegressor(), {}],\n",
    "    'Catboost': [catboost.CatBoostRegressor(), {'verbose': False}],\n",
    "    'KTBoost': [KTBoost.BoostingRegressor(), {}],\n",
    "    'XGBoost': [xgboost.XGBRegressor(), {}]}\n",
    "\n",
    "    x, y, xtest, ytest = get_train_test_data(nobs, noise_std, linear)\n",
    "    \n",
    "    for key, value in methods.items():\n",
    "        value[0].fit(x, y, **value[1])\n",
    "    \n",
    "    plt.figure(figsize=[10, 5])\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(y, 'ok', label='Observations')\n",
    "    \n",
    "    for key, value in methods.items():\n",
    "        plt.plot(value[0].predict(x), label=key)\n",
    "    plt.title('Training')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(ytest, 'ok', label='Observations')\n",
    "    for key, value in methods.items():\n",
    "        plt.plot(value[0].predict(xtest), label=key)\n",
    "    plt.title('Testing')\n",
    "    plt.legend()\n",
    "    \n",
    "compare_methods_widget = interactive(func, {'manual': True}, nobs=(10, 1000), noise_std=(0, 1, 0.1), linear=[('True', True), ('False', False)])\n",
    "display(compare_methods_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601b32b0-5dd7-4c59-8d2f-df6f4c7a7454",
   "metadata": {},
   "source": [
    "# Compare probabilistic predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce127b72-0e4c-4a6f-92e8-1322508c1660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae9cdee0ab8418ca88985515111fd6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=505, description='nobs', max=1000, min=10), FloatSlider(value=0.0, descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "def func(nobs, noise_std, linear, posterior_sampling):\n",
    "    x, y = linear_data(nobs, noise_std)\n",
    "    xtest, ytest = linear_data(nobs, noise_std)\n",
    "\n",
    "    ngb = ngboost.NGBRegressor()\n",
    "    catgb = catboost.CatBoostRegressor(posterior_sampling=posterior_sampling, loss_function='RMSEWithUncertainty')\n",
    "\n",
    "    x, y, xtest, ytest = get_train_test_data(nobs, noise_std, linear)\n",
    "    \n",
    "    ngb.fit(x, y)\n",
    "    catgb.fit(x, y, verbose=False)\n",
    "\n",
    "    plt.figure(figsize=[10, 5])\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(y, 'ok', label='Observations')\n",
    "    pred_dist = ngb.pred_dist(x)\n",
    "    mu = pred_dist.params['loc']\n",
    "    std = pred_dist.params['scale']\n",
    "    line, = plt.plot(mu, lw=2, label='NGB Predicted $\\mu$')\n",
    "    plt.fill_between(\n",
    "        line.get_xdata(), (mu - 2*std), (mu + 2*std), color=line.get_color(), alpha=0.4,\n",
    "        label='NGB Predicted $\\mu \\pm 2*\\sigma$')\n",
    "    predictions = catgb.predict(x)\n",
    "    #ensemble_predictions = catgb.virtual_ensembles_predict(x, prediction_type='VirtEnsembles')\n",
    "    #mins = np.min(ensemble_predictions, axis=1)\n",
    "    #maxs = np.max(ensemble_predictions, axis=1)\n",
    "    line, = plt.plot(predictions[:, 0], lw=2, label='Conditional mean, Catboost')\n",
    "    plt.fill_between(\n",
    "    line.get_xdata(), \n",
    "    predictions[:, 0]-2*np.sqrt(predictions[:, 1]), predictions[:, 0]+2*np.sqrt(predictions[:, 1]), color=line.get_color(), alpha=0.4,\n",
    "    label='Catboost $\\mu \\pm 2*\\sigma$')\n",
    "    #plt.fill_between(\n",
    "    #    line.get_xdata(), \n",
    "    #    mins[:, 0], maxs[:, 0], color=line.get_color(), alpha=0.4,\n",
    "    #    label='Catboost min and max')\n",
    "    plt.legend()\n",
    "    plt.title('Training')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(ytest, 'ok', label='Observations')\n",
    "    pred_dist = ngb.pred_dist(xtest)\n",
    "    mu = pred_dist.params['loc']\n",
    "    std = pred_dist.params['scale']\n",
    "    line, = plt.plot(mu, lw=2, label='NGB Predicted $\\mu$')\n",
    "    plt.fill_between(\n",
    "        line.get_xdata(), (mu - 2*std), (mu + 2*std), color=line.get_color(), alpha=0.4,\n",
    "        label='NGB Predicted $\\mu \\pm 2*\\sigma$')\n",
    "    predictions = catgb.predict(xtest)\n",
    "    #ensemble_predictions = catgb.virtual_ensembles_predict(xtest, prediction_type='VirtEnsembles', virtual_ensembles_count=10)\n",
    "    #mins = np.min(ensemble_predictions, axis=1)\n",
    "    #maxs = np.max(ensemble_predictions, axis=1)\n",
    "    line, = plt.plot(predictions[:, 0], lw=2, label='Conditional mean, Catboost')\n",
    "    plt.fill_between(\n",
    "        line.get_xdata(),  predictions[:, 0]-2*np.sqrt(predictions[:, 1]), predictions[:, 0]+2*np.sqrt(predictions[:, 1]), \n",
    "        color=line.get_color(), alpha=0.4, label='Catboost $\\mu \\pm 2*\\sigma$')\n",
    "    plt.title('Test')\n",
    "    \n",
    "prob_methods_widget = interactive(func, {'manual': True}, nobs=(10, 1000), noise_std=(0, 1, 0.1), linear=[('True', True), ('False', False)], posterior_sampling=[('True', True), ('False', False)])\n",
    "display(prob_methods_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3ab4da-1fd6-4106-97ff-7bb30d1ddba1",
   "metadata": {},
   "source": [
    "# Time to fit methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "391cd2e6-6b75-4a01-b3fd-a2972fe87b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, xtest, ytest = get_train_test_data(nobs=10000, noise_std=0.5, linear=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defa0e22-d616-459a-95d4-a1ec77c23aef",
   "metadata": {},
   "source": [
    "## NGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebefcbff-0b75-4926-b8a0-44df1e861400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=3.6073 val_loss=0.0000 scale=1.0000 norm=7.3383\n",
      "[iter 100] loss=3.0563 val_loss=0.0000 scale=1.0000 norm=3.7772\n",
      "[iter 200] loss=2.2904 val_loss=0.0000 scale=2.0000 norm=3.1227\n",
      "[iter 300] loss=1.5174 val_loss=0.0000 scale=2.0000 norm=1.7511\n",
      "[iter 400] loss=0.9957 val_loss=0.0000 scale=2.0000 norm=1.3642\n",
      "Wall time: 22.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NGBRegressor(random_state=RandomState(MT19937) at 0x1E17FD30940)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ngb = ngboost.NGBRegressor()\n",
    "ngb.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431123ff-b25e-4767-9099-7bdd2df196ac",
   "metadata": {},
   "source": [
    "## Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3528a874-db8e-4592-9149-6c5b62a2f708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.94 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x1e12369f580>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "catgb = catboost.CatBoostRegressor(posterior_sampling=True, loss_function='RMSEWithUncertainty')\n",
    "catgb.fit(x, y, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afeb4ba1-0716-4aea-be37-392b733160ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.49 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x1e1236626a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "catgb = catboost.CatBoostRegressor(posterior_sampling=False, loss_function='RMSEWithUncertainty')\n",
    "catgb.fit(x, y, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73a352d1-b91a-4d97-8d40-68489acd09cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.86 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x1e1236528b0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "catgb = catboost.CatBoostRegressor(posterior_sampling=True, loss_function='RMSE')\n",
    "catgb.fit(x, y, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfec4778-159a-4435-8afd-5bef8f6c5ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x1e121562ca0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "catgb = catboost.CatBoostRegressor(posterior_sampling=False, loss_function='RMSE')\n",
    "catgb.fit(x, y, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a691c3-50bf-431a-8297-59db355d4d36",
   "metadata": {},
   "source": [
    "## SKLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7ae1d76-0494-48f2-8240-8b6ce6bfc5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.27 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "skgb = GradientBoostingRegressor()\n",
    "skgb.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8983ceb8-f606-44a1-a6b5-f7b704960b53",
   "metadata": {},
   "source": [
    "## KTBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55bbdcf7-d35b-4cbd-af79-f073f1f9d94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.98 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BoostingRegressor()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ktb = KTBoost.BoostingRegressor()\n",
    "ktb.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f5c583-a2fa-4eaf-9f5d-70822857f5cb",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a719b913-bcda-4c20-8dc6-738022972dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.64 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=12, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "xgb = xgboost.XGBRegressor()\n",
    "xgb.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cbc19c-c094-43d9-bdb3-f2b34fe50973",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
